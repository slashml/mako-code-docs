---
title: 'Quick Start'
description: 'This guide will help you get up and running with Mako Code quickly for your data analysis workflows.
'
---

## Getting Started

Once you have [installed Mako Code](./installation), here's how to start analyzing data:

1. Import data using `⌘/Ctrl + Shift + I`
2. Open the data management sidebar with `⌘/Ctrl + D`
3. Find your dataset in the list
4. Click the dataset name to view details including:
   - Column names and types
   - Sample data preview
   - Documentation notes
5. Click the menu (⋯) next to the dataset and select "Analyze"
6. This opens a new tab with pre-populated Polars code to start your analysis

## Interface Overview

The Mako Code interface is designed for efficient data analysis:

![Mako Code Editor Interface](/img/code-editor.png)

The interface provides:
- Left sidebar: Saved functions, Polars API docs link, Mako docs and keyboard shortcuts
- Right sidebar: Data management (toggle with `⌘/Ctrl + D`)
- Editor tabs: Code, visualization and documentation views
- Output panel: View results directly below your code

## Dataset Preview

When working with datasets, you can view and explore your data with the built-in preview:

![Dataset Preview Interface](/img/dataset-preview.png)

The dataset preview shows:
- Paginated data view
- Column types and schema information
- Context panel for dataset documentation
- Quick navigation controls

## Key Shortcuts

- `⌘/Ctrl + Enter`: Run current file
- `⌘/Ctrl + Shift + P`: New Polars file
- `⌘/Ctrl + Shift + L`: New SQL file
- `⌘/Ctrl + Shift + B`: New Bokeh visualization
- `⌘/Ctrl + S`: Save Context File
- `⌘/Ctrl + E`: Export your current tab script
- `⌘/Ctrl + Shift + I`: Import data
- `⌘/Ctrl + D`: Toggle data management sidebar

## Example Analysis

Here's a simple example of analyzing data with Polars in Mako Code:

```python
import polars as pl

# Load dataset (Mako automatically provides access to your imported datasets)
df = pl.read_parquet("your_dataset.parquet")

# Quick data exploration
print(df.head())
print(df.describe())

# Simple transformation
result = df.filter(pl.col("value") > 100).group_by("category").agg(
    pl.count().alias("count"),
    pl.sum("amount").alias("total_amount"),
    pl.mean("value").alias("average_value")
)

# Display the result
print(result)
```

## Next Steps

Now that you've seen the basics, check out these resources to learn more:

- [Core Concepts](../concepts/basic-concepts)
- [Core Features](../features/core-features)
- [Advanced Usage](../features/advanced-usage)
